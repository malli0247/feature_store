{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version 3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"python version {}\".format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CG Notes / Updates: \n",
    "1. .env approach for creating Session object (optional, env specific)\n",
    "2. validate installation and import of snowpark modin module\n",
    "3. demonstrate use of modin.pandas to  generate Snowpark Dataframe, locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "storing creds in an .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/cgoyette/Documents/GitHub/feature_store'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load from local .env file\n",
    "load_dotenv(\".env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cgoyette'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.getenv('SNOWFLAKE_USER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "connection_details = {\n",
    "  \"account\":  os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "  \"user\": os.environ[\"SNOWFLAKE_USER\"],\n",
    "  \"password\": os.environ[\"SNOWFLAKE_USER_PASSWORD\"],\n",
    "  \"role\": os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session = Session.builder.configs(connection_details).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Snowpark Python package into the Python virtual environment (automatically installs the appropriate version of PyArrow)\n",
    "# pip install snowflake-snowpark-python\n",
    "# ! pip install \"snowflake-snowpark-python[modin]\"\n",
    "# pip install modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-snowpark-python[modin] in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (1.23.0)\n",
      "Requirement already satisfied: setuptools>=40.6.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-snowpark-python[modin]) (75.1.0)\n",
      "Requirement already satisfied: wheel in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-snowpark-python[modin]) (0.44.0)\n",
      "Requirement already satisfied: snowflake-connector-python<4.0.0,>=3.10.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-snowpark-python[modin]) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-snowpark-python[modin]) (4.12.2)\n",
      "Requirement already satisfied: pyyaml in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-snowpark-python[modin]) (6.0.2)\n",
      "Requirement already satisfied: cloudpickle!=2.1.0,!=2.2.0,<=2.2.1,>=1.6.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-snowpark-python[modin]) (2.2.1)\n",
      "Collecting modin==0.28.1 (from snowflake-snowpark-python[modin])\n",
      "  Using cached modin-0.28.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pandas==2.2.1 (from modin==0.28.1->snowflake-snowpark-python[modin])\n",
      "  Using cached pandas-2.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: packaging>=21.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from modin==0.28.1->snowflake-snowpark-python[modin]) (24.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from modin==0.28.1->snowflake-snowpark-python[modin]) (2.1.2)\n",
      "Collecting fsspec>=2022.11.0 (from modin==0.28.1->snowflake-snowpark-python[modin])\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from modin==0.28.1->snowflake-snowpark-python[modin]) (6.0.0)\n",
      "Collecting numpy>=1.22.4 (from modin==0.28.1->snowflake-snowpark-python[modin])\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from pandas==2.2.1->modin==0.28.1->snowflake-snowpark-python[modin]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from pandas==2.2.1->modin==0.28.1->snowflake-snowpark-python[modin]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from pandas==2.2.1->modin==0.28.1->snowflake-snowpark-python[modin]) (2024.2)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (1.17.1)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (43.0.1)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (24.2.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (2.9.0)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (2024.8.30)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (3.16.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (4.3.6)\n",
      "Requirement already satisfied: tomlkit in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (0.13.2)\n",
      "Collecting pyarrow (from snowflake-connector-python[pandas]<4.0.0,>=3.10.0; extra == \"modin\"->snowflake-snowpark-python[modin])\n",
      "  Using cached pyarrow-17.0.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (2.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from requests<3.0.0->snowflake-connector-python<4.0.0,>=3.10.0->snowflake-snowpark-python[modin]) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/syngenta_fs/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.1->modin==0.28.1->snowflake-snowpark-python[modin]) (1.16.0)\n",
      "Using cached modin-0.28.1-py3-none-any.whl (1.2 MB)\n",
      "Using cached pandas-2.2.1-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached pyarrow-17.0.0-cp310-cp310-macosx_11_0_arm64.whl (27.2 MB)\n",
      "Installing collected packages: numpy, fsspec, pyarrow, pandas, modin\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "Successfully installed fsspec-2024.9.0 modin-0.28.1 numpy-1.26.4 pandas-2.2.1 pyarrow-17.0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install \"snowflake-snowpark-python[modin]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Snowflake snowpark sesssion \n",
    "#### with SSO through a web browser"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# If you have configured Snowflake to use single sign-on (SSO), you can configure your client application to use browser-based SSO for authentication.\n",
    "from snowflake.snowpark import Session\n",
    "connection_parameters = {\n",
    "   \"account\":\"ska58151.us-east-1\",\n",
    "   \"user\":\"MALLESWARI.GELLI@SYNGENTA.COM\",\n",
    "   \"role\":\"FEATLK_NONPROD_DEVELOPER_ROLE\",\n",
    "   \"database\":\"FEATLK_DEV\",\n",
    "   \"schema\":\"FEATLK_DATA\",\n",
    "   \"warehouse\":\"FEATLK_INGEST_DEV\",\n",
    "   \"authenticator\":\"externalbrowser\"\n",
    "}\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<snowflake.snowpark.session.Session: account=\"ska58151\", role=\"FEATLK_NONPROD_DEVELOPER_ROLE\", database=\"FEATLK_DEV\", schema=\"FEATLK_DATA\", warehouse=\"FEATLK_INGEST_DEV\">\n"
     ]
    }
   ],
   "source": [
    "print(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you have configured Snowflake to use single sign-on (SSO), you can configure your client application to use browser-based SSO for authentication.\n",
    "import json\n",
    "from snowflake.snowpark import Session\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "print(connection_parameters)\n",
    "# connect to the database\n",
    "session = Session.builder.configs(connection_parameters).create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark.modin.plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: Couldn't resolve\n",
    "ModuleNotFoundError: No module named 'snowflake.snowpark.modin'\n",
    "\n",
    "Can't i run `snowflake pandas` out side of snowflake notebooks? \n",
    "\n",
    "### CG note\n",
    "\n",
    "Yes, you can use modin.pandas locally\n",
    "Ref: (https://docs.snowflake.com/developer-guide/snowpark/python/pandas-on-snowflake)\n",
    "\n",
    "However, in the cell below, you've re-imported pandas as pd. modin.pandas is a 'drag and drop' replacement for pandas that enables the scale & performance benefits of the Snowpark Pandas APIs. \n",
    "\n",
    "There are some limitations however, when it comes to integrating with 3rd party libraries: (https://docs.snowflake.com/developer-guide/snowpark/python/pandas-on-snowflake#limitations)\n",
    "\n",
    "---\n",
    "\n",
    "Note that below, please avoid re-importing native pandas, after importing modin.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import col\n",
    "#CG note: commented out this line\n",
    "#import pandas as pd\n",
    "import snowflake.snowpark as snowpark\n",
    "\n",
    "# Create a Snowpark session with a default connection.\n",
    "from snowflake.snowpark.session import Session\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "table_name = \"NYC_YELLOW_TRIPS\"\n",
    "\n",
    "def load_data(session: snowpark.Session, database:str, schema:str, table_name:str): \n",
    "    '''loads data from a table exist in active session'''  \n",
    "    \n",
    "    # Step 1 :- Getting data from tables (Snowflake table)  \n",
    "    source_table = f\"{database}.{schema}.{table_name}\" \n",
    "    \n",
    "\n",
    "    # Step2: Create a snowpark DataFrame from source table.\n",
    "    snowpark_df = session.table(source_table)\n",
    "    \n",
    "    # Step3: Create a Snowpark pandas DataFrame from existing Snowflake table\n",
    "    #snowpark_pandas_df = pd.read_snowflake(source_table)\n",
    "\n",
    "    # Step3: Convert snowpark Dataframe into your choice (pandas df, snowpark pandas, spark df)\n",
    "    # Step3a: Converting the data to pandas dataframe\n",
    "    pandas_df = snowpark_df.to_pandas()\n",
    "\n",
    "    # converting a Pandas DataFrame into a Spark DataFrame.\n",
    "    \n",
    "    # return snowpark_df\n",
    "    return pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CG Demo of creating pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 'Big Bear', 8],[2, 'Big Bear', 10],[3, 'Big Bear', None],\n",
    "                    [1, 'Tahoe', 3],[2, 'Tahoe', None],[3, 'Tahoe', 13],\n",
    "                    [1, 'Whistler', None],['Friday', 'Whistler', 40],[3, 'Whistler', 25]],\n",
    "                    columns=[\"DAY\", \"LOCATION\", \"SNOWFALL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>SNOWFALL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Big Bear</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Big Bear</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Big Bear</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Whistler</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Whistler</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Whistler</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DAY  LOCATION  SNOWFALL\n",
       "0       1  Big Bear       8.0\n",
       "1       2  Big Bear      10.0\n",
       "2       3  Big Bear       NaN\n",
       "3       1     Tahoe       3.0\n",
       "4       2     Tahoe       NaN\n",
       "5       3     Tahoe      13.0\n",
       "6       1  Whistler       NaN\n",
       "7  Friday  Whistler      40.0\n",
       "8       3  Whistler      25.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe below the modin.pandas.dataframe type. This is a Snowpark pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modin.pandas.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DAY', 'LOCATION', 'SNOWFALL'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.to_snowpark(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snowflake.snowpark.dataframe.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:snowflake.snowpark.modin.plugin.utils.warning_message:The current operation leads to materialization and can be slow if the data is large!\n"
     ]
    }
   ],
   "source": [
    "df_pandas = df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that .to_pandas() converts Snowpark pandas DF to native pandas df. Native pandas methods can then be used on this dataframe, directly via modin.pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "End (Colin Demo)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print out the first 10 rows of snowpark df\n",
    "import time\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "snowpark_df= load_data(session,database,schema,table_name)\n",
    "print(snowpark_df.show())\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "print(\"snowpark_df printing 10 rows took:\", t1-t0, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To print out the first 10 rows of pandas df\n",
    "import time\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "pandas_df= load_data(session,database,schema,table_name)\n",
    "print(\"Size of df:\", pandas_df.shape)\n",
    "print(pandas_df.head(5))\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "print(\"pandas_df printing 10 rows took:\", t1-t0, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Transformations\n",
    "\n",
    "- Features aggregated by location id and refreshed every 12 hours -> AVG_FARE_1H (float), AVG_FARE_10H (float)\n",
    "- Features per trip refreshed every day - PASSENGER_COUNT, TRIP_DISTANCE, FARE_AMOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f_trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "f_trip_data = data_set[[\"TRIP_ID\",\"PASSENGER_COUNT\",\"TRIP_DISTANCE\",\"FARE_AMOUNT\"]]\n",
    "print(f_trip_data.head())\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "print(\"df.head printing took:\", t1-t0, \"seconds\")\n",
    "\n",
    "# and if you really want your answer in minutes:\n",
    "#print(f\"In minutes: {(t1-t0)/60}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert pandas df to snowpark df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpark_df = session.create_dataframe(data=f_trip_data)\n",
    "snowpark_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f_location_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.dtypes[\"TPEP_DROPOFF_DATETIME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set[\"TPEP_DROPOFF_DATETIME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.dtypes[\"TPEP_DROPOFF_DATETIME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set[\"reach_minutes\"]= (data_set[\"TPEP_DROPOFF_DATETIME\"]).dt.total_seconds()/60\n",
    "data_set[\"reach_minutes\"]= data_set[\"reach_minutes\"].astype(int)\n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.sort_values(by=[\"TPEP_DROPOFF_DATETIME\"],ascending=False)[[\"TPEP_DROPOFF_DATETIME\",\"DOLOCATIONID\",\"trip_time_minutes\",\"FARE_AMOUNT\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_FARE_1H= data_set.groupby([\"DOLOCATIONID\"]).apply(lambda x: \"FARE_AMOUNT\"]]\n",
    "f_loc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create multiple entities test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"entities_list.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "entities = json.load(open(\"entities.json\", \"r\"))\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in enumerate(df.values):\n",
    "    print(index, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in enumerate(df.values):\n",
    "    for i in index:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feastore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
